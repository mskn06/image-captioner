{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"flickr30k_images/results.txt\",'r') as f:\n",
    "    info = f.read()\n",
    "info = info.split('\\n')\n",
    "information = []\n",
    "for i in range(1,len(info)-1):\n",
    "    information.append(info[i].split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = {}\n",
    "for i in information:\n",
    "    if descriptions.get(i[0]) is None:\n",
    "        descriptions[i[0]] = []\n",
    "    descriptions[i[0]].append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]+\",\" \",sentence)\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    sentence = [s for s in sentence if len(s)>1]\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,caption_list in descriptions.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = clean_text(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"descriptions.txt\",'w') as f:\n",
    "    f.write(str(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions = {}\n",
    "\n",
    "for img_id in descriptions.keys():\n",
    "    train_descriptions[img_id] = []\n",
    "    for cap in descriptions[img_id]:\n",
    "        cap_to_append = \"<s> \"+cap+\" <e>\"\n",
    "        train_descriptions[img_id].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_descriptions.pkl', 'wb') as f:\n",
    "        pickle.dump(train_descriptions, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions = None\n",
    "with open('train_descriptions.pkl', 'rb') as f:\n",
    "        train_descriptions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31783"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "\n",
    "for key in descriptions.keys():\n",
    "    [total_words.append(i) for des in descriptions[key] for i in des.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679080"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18054\n",
      "5118\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(total_words)\n",
    "freq = dict(counter)\n",
    "print(len(freq))\n",
    "\n",
    "threshold=10\n",
    "shortlist = [x for x in freq.keys() if freq[x]>threshold]\n",
    "\n",
    "print(len(shortlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "for i,word in enumerate(shortlist):\n",
    "    word_to_index[word] = i+1\n",
    "    index_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index[\"<s>\"] = 5119\n",
    "index_to_word[5119] = \"<s>\"\n",
    "\n",
    "word_to_index[\"<e>\"] = 5120\n",
    "index_to_word[5120] = \"<e>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_to_index.pkl', 'wb') as f:\n",
    "        pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_word.pkl', 'wb') as f:\n",
    "        pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"glove.6B.50d.txt\")\n",
    "\n",
    "embedding_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:],dtype='float')\n",
    "    embedding_index[word] = word_embedding\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "    emb_dim = 50\n",
    "    matrix = np.zeros((vocab_size,emb_dim))\n",
    "    for word,idx in word_to_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5121, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = get_embedding_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(embedding_matrix, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_train_features = None\n",
    "with open(\"encoding_train_features.pkl\",'rb') as f:\n",
    "    encoding_train_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
